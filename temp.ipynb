{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'have'), (1, 'you'), (2, 'ever'), (3, 'read'), (4, '/'), (5, 'watched'), (6, 'game'), (7, 'of'), (8, 'throne'), (9, '##s'), (10, '?'), (11, 'in'), (12, 'that'), (13, 'show'), (14, 'house'), (15, 'lan'), (16, '##nist'), (17, '##er'), (18, 'has'), (19, 'crimson'), (20, 'red'), (21, 'as'), (22, 'their'), (23, 'family'), (24, 'color'), (25, '.'), (26, '[SEP]'), (27, 'i'), (28, 'have'), (29, 'heard'), (30, 'so'), (31, 'much'), (32, 'about'), (33, 'it'), (34, ','), (35, 'i'), (36, 'have'), (37, 'never'), (38, 'watched'), (39, 'it'), (40, 'before'), (41, '!'), (42, 'it'), (43, 'looks'), (44, 'like'), (45, 'the'), (46, 'series'), (47, 'is'), (48, 'ending'), (49, 'next'), (50, 'year'), (51, 'after'), (52, 'eight'), (53, 'seasons'), (54, '!'), (55, '!')]\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장과 토큰 위치\n",
    "sentence =  \"Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color. [SEP] I have heard so much about It, I have never watched it before! It looks like the series is ending next year after eight seasons!!\"\n",
    "# token_index = 6  # [MASK]로 대체할 토큰의 위치\n",
    "candidates = ['\"crimson. I prefer baby pink\"', 'red', 'Game of Thrones', 'House Lannister']  # 후보 단어 리스트\n",
    "\n",
    "# 문장을 토큰화하고 [MASK] 토큰으로 지정된 위치의 단어 대체\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "#print index and token in tokens\n",
    "print([(i,t) for i,t in enumerate(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'have',\n",
       " 'you',\n",
       " 'ever',\n",
       " 'read',\n",
       " '/',\n",
       " 'watched',\n",
       " 'game',\n",
       " 'of',\n",
       " 'throne',\n",
       " '##s',\n",
       " '?',\n",
       " 'in',\n",
       " 'that',\n",
       " 'show',\n",
       " 'house',\n",
       " 'lan',\n",
       " '##nist',\n",
       " '##er',\n",
       " 'has',\n",
       " 'crimson',\n",
       " 'red',\n",
       " 'as',\n",
       " 'their',\n",
       " 'family',\n",
       " 'color',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'i',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'so',\n",
       " 'much',\n",
       " 'about',\n",
       " '[MASK]',\n",
       " ',',\n",
       " 'i',\n",
       " 'have',\n",
       " 'never',\n",
       " 'watched',\n",
       " 'it',\n",
       " 'before',\n",
       " '!',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'the',\n",
       " 'series',\n",
       " 'is',\n",
       " 'ending',\n",
       " 'next',\n",
       " 'year',\n",
       " 'after',\n",
       " 'eight',\n",
       " 'seasons',\n",
       " '!',\n",
       " '!',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index = 33\n",
    "tokens[token_index] = '[MASK]'\n",
    "mask_token_index = tokens.index('[MASK]')\n",
    "\n",
    "# [CLS]와 [SEP] 토큰 추가\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "mask_token_index += 1  # [CLS] 토큰이 추가되어 인덱스 조정\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('red', 0.0003169028495904058),\n",
       " ('\"crimson. I prefer baby pink\"', 8.241360660576902e-08),\n",
       " ('Game of Thrones', 8.241360660576902e-08),\n",
       " ('House Lannister', 8.241360660576902e-08)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 문장과 토큰 위치\n",
    "sentence =  \"Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color. [SEP] I have heard so much about It, I have never watched it before! It looks like the series is ending next year after eight seasons!!\"\n",
    "# token_index = 6  # [MASK]로 대체할 토큰의 위치\n",
    "candidates = ['\"crimson. I prefer baby pink\"', 'red', 'Game of Thrones', 'House Lannister']  # 후보 단어 리스트\n",
    "\n",
    "# 문장을 토큰화하고 [MASK] 토큰으로 지정된 위치의 단어 대체\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "#print index and token in tokens\n",
    "# print([(i,t) for i,t in enumerate(tokens)])\n",
    "\n",
    "token_index = 33\n",
    "tokens[token_index] = '[MASK]'\n",
    "mask_token_index = tokens.index('[MASK]')\n",
    "\n",
    "# [CLS]와 [SEP] 토큰 추가\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "mask_token_index += 1  # [CLS] 토큰이 추가되어 인덱스 조정\n",
    "\n",
    "# 토큰을 모델의 입력 형태로 변환\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_tensor = torch.tensor([input_ids])\n",
    "\n",
    "# [MASK] 위치에 대한 예측 수행\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# 후보 단어들의 확률 계산\n",
    "candidate_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
    "probs = torch.softmax(predictions[0, mask_token_index], dim=-1)\n",
    "candidate_probs = probs[candidate_ids]\n",
    "\n",
    "# 후보 단어들과 그 확률 출력\n",
    "results = {}\n",
    "for word, prob in zip(candidates, candidate_probs):\n",
    "    # print(f\"{word}: {prob.item()}\")\n",
    "    results[word] = prob.item()\n",
    "\n",
    "# 확률이 높은 순서대로 출력\n",
    "sorted(results.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils_select_predictions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import json, jsonlines\n",
    "import logging\n",
    "from collections import Counter\n",
    "import argparse\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "\n",
    "def write_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Write data to a JSON file. w/ args.output_file\n",
    "    \"\"\"\n",
    "    logging.info(f'Writing {len(data)} items to {file_path}.')\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    \n",
    "def evaluate_sentence_with_candidates(sentence_template, candidates):\n",
    "    # 모델과 토크나이저 초기화\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    model.eval()\n",
    "\n",
    "    # 로그 확률을 계산하는 함수\n",
    "    def score(sentence):\n",
    "        tokenize_input = tokenizer.encode(sentence)\n",
    "        tensor_input = torch.tensor([tokenize_input])\n",
    "        with torch.no_grad():\n",
    "            loss = model(tensor_input, labels=tensor_input)[0]\n",
    "        return -loss.item()\n",
    "\n",
    "    # 각 후보에 대한 문장의 확률 계산\n",
    "    scores = {}\n",
    "    for candidate in candidates:\n",
    "        candidate_sentence = sentence_template.format(candidate)\n",
    "        candidate_score = score(candidate_sentence)\n",
    "        scores[candidate] = candidate_score\n",
    "\n",
    "    # 확률이 높은 순서대로 후보 정렬 및 출력\n",
    "    sorted_candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_candidates\n",
    "\n",
    "# def generate_filled_sentences(found_pronoun, context, response, pronoun_index, candidates):\n",
    "#     # 문맥에서 마지막 두 문장을 가져옵니다.\n",
    "#     context_part = \" \".join(context[-2:])\n",
    "    \n",
    "#     # 대응하는 응답에서 대명사를 {}로 대체합니다.\n",
    "#     doc = nlp(response)\n",
    "#     if doc[pronoun_index] == found_pronoun: # 지시대명사를 빈칸으로 대체하기\n",
    "#         doc[pronoun_index] = '{}'\n",
    "#     response_with_placeholder = \" \".join(doc)\n",
    "    \n",
    "#     # 완성된 문장 템플릿을 생성합니다.\n",
    "#     sentence_template = f\"{context_part} {response_with_placeholder}\"\n",
    "    \n",
    "#     # 각 후보에 대한 문장의 확률을 계산하고 정렬합니다.\n",
    "#     sorted_candidates = evaluate_sentence_with_candidates(sentence_template, candidates)\n",
    "    \n",
    "#     return sorted_candidates\n",
    "\n",
    "def generate_filled_sentences(found_pronoun, context, response, pronoun_index, candidates):\n",
    "    # 문맥에서 마지막 두 문장을 가져옵니다.\n",
    "    context_part = \" \".join(context[-2:])\n",
    "    \n",
    "    # 대응하는 응답을 토큰화합니다.\n",
    "    doc = nlp(response)\n",
    "    tokens = [token.text for token in doc]  # spacy 토큰을 문자열 리스트로 변환\n",
    "    \n",
    "    # 지시대명사의 인덱스에 해당하는 토큰을 '{}'로 대체합니다.\n",
    "    if tokens[pronoun_index] == found_pronoun:\n",
    "        tokens[pronoun_index] = '{}'\n",
    "    response_with_placeholder = \" \".join(tokens)  # 수정된 토큰 리스트를 다시 문자열로 결합\n",
    "    \n",
    "    # 완성된 문장 템플릿을 생성합니다.\n",
    "    sentence_template = f\"{context_part} {response_with_placeholder}\"\n",
    "    \n",
    "    # 각 후보에 대한 문장의 확률을 계산하고 정렬합니다.\n",
    "    sorted_candidates = evaluate_sentence_with_candidates(sentence_template, candidates)\n",
    "    \n",
    "    return sorted_candidates\n",
    "\n",
    "def select_predictions(frame_file, pred_file, output_file):\n",
    "    # logging.info('>>>>>>>>>>>>>>>>> Start selecting predictions.')\n",
    "    print('>>>>>>>>>>>>>>>>> Start selecting predictions.')\n",
    "    frames = []\n",
    "    predictions = []\n",
    "    with jsonlines.open(frame_file) as reader:\n",
    "        for line in reader:\n",
    "            frames.append(line)\n",
    "    with open(pred_file, 'r') as f:\n",
    "        predictions = json.load(f)\n",
    "\n",
    "    # assert len(frames) == len(predictions)\n",
    "    # logging.info('>>>>>>>>>>>>>>>>> len(frames): {}'.format(len(frames)))\n",
    "    # logging.info('>>>>>>>>>>>>>>>>> len(preds): {}'.format(len(predictions)))\n",
    "    print('>>>>>>>>>>>>>>>>> len(frames): {}'.format(len(frames)))\n",
    "    print('>>>>>>>>>>>>>>>>> len(preds): {}'.format(len(predictions)))\n",
    "    return\n",
    "    results = {}\n",
    "\n",
    "    qasid_empty = []\n",
    "    for i, frame in enumerate(frames):\n",
    "        candidates = [cand[\"text\"] for cand in predictions[str(i)]]\n",
    "        sorted_candidates = generate_filled_sentences(\n",
    "                                                        frame['found_pronoun'],\n",
    "                                                        frame[\"context_text\"],\n",
    "                                                        frame[\"orig_response\"],\n",
    "                                                        frame[\"pronoun_index\"],\n",
    "                                                        candidates\n",
    "                                                    )   \n",
    "        \n",
    "        if not sorted_candidates: # No predictions: \"empty\" in predictsion_.json, [] in nbest_predictions_.json\n",
    "            logging.info(f'[Empty] ---> {frame[\"qas_id\"]}')\n",
    "            qasid_empty.append(frame['qas_id'])\n",
    "        else:\n",
    "            predicted_noun = sorted_candidates[0][0]\n",
    "            logging.info(f'[{predicted_noun}] ---> {frame[\"qas_id\"]}')\n",
    "            results[frame['qas_id']] = [predicted_noun]\n",
    "        # break\n",
    "        # print logging every 10% in for loop\n",
    "        if i % (len(frames) // 10) == 0:\n",
    "            logging.info(f'>>>>>>>>>>>>>>>>> {i} / {len(frames)} done.')\n",
    "    write_json(results, output_file)\n",
    "    print(f'>>>>>>>>>>>>>>>>> The Number of empty predictions: {len(qasid_empty)} out of {len(frames)}.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialfact / Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> Start selecting predictions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> len(frames): 7411\n",
      ">>>>>>>>>>>>>>>>> len(preds): 7411\n"
     ]
    }
   ],
   "source": [
    "# [1] dialfact valid\n",
    "FRAME_FILE='/data/scratch/acw722/corefbert/result/resolved_data/dialfact/dialfact_valid_with_pronouns.jsonl'\n",
    "PRED_FILE='/data/scratch/acw722/corefbert/result/inference/nbest_predictions_dialfact_valid.json'\n",
    "OUTPUT_FILE='/data/scratch/acw722/corefbert/result/inference/thebest_predictions_dialfact_valid.json'\n",
    "\n",
    "select_predictions(FRAME_FILE, PRED_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> Start selecting predictions.\n",
      ">>>>>>>>>>>>>>>>> len(frames): 10155\n",
      ">>>>>>>>>>>>>>>>> len(preds): 10155\n"
     ]
    }
   ],
   "source": [
    "# [1] dialfact test\n",
    "FRAME_FILE='/data/scratch/acw722/corefbert/result/resolved_data/dialfact/dialfact_test_with_pronouns.jsonl'\n",
    "# PRED_FILE='/data/scratch/acw722/corefbert/result/inference/nbest_predictions_dialfact_test.json'\n",
    "PRED_FILE='/data/scratch/acw722/corefbert/result/inference/predictions_dialfact_test.json'\n",
    "OUTPUT_FILE='/data/scratch/acw722/corefbert/result/inference/thebest_predictions_dialfact_test.json'\n",
    "\n",
    "select_predictions(FRAME_FILE, PRED_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> Start selecting predictions.\n",
      ">>>>>>>>>>>>>>>>> len(frames): 1463\n",
      ">>>>>>>>>>>>>>>>> len(preds): 1463\n"
     ]
    }
   ],
   "source": [
    "# [3] augwow dev\n",
    "FRAME_FILE='/data/scratch/acw722/corefbert/result/resolved_data/augwow/augwow_dev_with_pronouns.jsonl'\n",
    "PRED_FILE='/data/scratch/acw722/corefbert/result/inference/nbest_predictions_augwow_dev.json'\n",
    "OUTPUT_FILE='/data/scratch/acw722/corefbert/result/inference/thebest_predictions_augwow_dev.json'\n",
    "\n",
    "select_predictions(FRAME_FILE, PRED_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>> Start selecting predictions.\n",
      ">>>>>>>>>>>>>>>>> len(frames): 168347\n",
      ">>>>>>>>>>>>>>>>> len(preds): 168347\n"
     ]
    }
   ],
   "source": [
    "# [4] augwow train\n",
    "FRAME_FILE='/data/scratch/acw722/corefbert/result/resolved_data/augwow/augwow_train_with_pronouns.jsonl'\n",
    "# PRED_FILE='/data/scratch/acw722/corefbert/result/inference/nbest_predictions_augwow_train.json'\n",
    "PRED_FILE='/data/scratch/acw722/corefbert/result/inference/predictions_augwow_train.json'\n",
    "OUTPUT_FILE='/data/scratch/acw722/corefbert/result/inference/thebest_predictions_augwow_train.json'\n",
    "\n",
    "select_predictions(FRAME_FILE, PRED_FILE, OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"Game of Thrones\"를 가장 자연스러운 선택으로 예측하는 데 있어서 GPT-2가 BERT보다 더 성공적이었던 이유?\n",
    "\n",
    "    - 학습 목표와 방식의 차이: GPT-2는 연속된 텍스트를 예측하는 언어 생성 모델입니다. 이는 주어진 문맥을 바탕으로 다음에 올 텍스트를 예측하는 방식으로 학습되며, 전체 문장의 흐름과 문맥적 자연스러움에 중점을 둡니다. 반면, BERT는 문장 내 빈칸을 채우는 방식(Masked Language Model, MLM)으로 학습되어, 주어진 문맥 내에서 단어나 구의 적합성을 평가하는 데 초점을 맞춥니다. 이러한 차이로 인해, 전체 문장의 자연스러움을 평가하는 작업에서 GPT-2가 더 유리할 수 있습니다.\n",
    "\n",
    "    - 언어 이해 및 생성 능력: GPT-2는 문장 생성 작업에 특화된 모델로, 주어진 문맥을 기반으로 문장을 이어 나가는 능력이 매우 뛰어납니다. 이는 모델이 전체 문장 구조와 문맥을 더 효과적으로 이해하고, 그에 따라 더 자연스러운 텍스트를 생성할 수 있음을 의미합니다. 따라서, \"Game of Thrones\"와 같이 특정 문맥에서 자연스럽게 등장할 수 있는 구나 문구를 예측하는 데 있어 GPT-2가 더 정확할 수 있습니다.\n",
    "\n",
    "    - 토큰 처리 방식의 차이: BERT는 주로 문장 내의 단일 토큰이나 짧은 구를 대상으로 학습되며, 한 번에 하나의 [MASK] 토큰만 예측합니다. 반면, GPT-2는 전체 문장을 생성하는 과정에서 여러 단어나 구를 연속적으로 예측할 수 있습니다. 이로 인해, \"Game of Thrones\"와 같이 여러 토큰으로 구성된 구나 문구를 더 자연스럽게 처리하고 예측할 수 있습니다.\n",
    "\n",
    "    - 이러한 이유들로 인해, 주어진 문장 내에서 \"Game of Thrones\"를 가장 적합한 선택으로 예측하는 데 GPT-2가 BERT보다 더 성공적일 수 있습니다. GPT-2의 학습 방식과 모델 구조는 전체 문장의 문맥적 자연스러움과 흐름을 더 잘 파악하고 반영할 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resolved all/subset 확인\n",
    "- original/resolved 각각 매칭확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matching_responses(json_list1, json_list2):\n",
    "    for json_obj1, json_obj2 in zip(json_list1, json_list2):\n",
    "        if json_obj1['id'] == json_obj2['id']:\n",
    "            print(json_obj1['response'])\n",
    "            print(json_obj2['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialfact/test/subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11809\n",
      "dict_keys(['context_id', 'id', 'data_type', 'context', 'response', 'evidence_list', 'response_label', 'type_label'])\n",
      "{'context_id': '588___9', 'id': '588___9--0', 'data_type': 'written', 'context': ['Hello! I was a cheerleader in high school. Do you have any experience with cheerleading? ', 'Cheerleading could be chanting or activity.', 'yes, it could be. By chanting, do you mean saying things in unison? ', 'Cheerleaders cheer for their team to root for them.', 'Yes, they do. I believe it gives the team a lot of momentum. ', 'Competitive routines can be from one to three minutes.', 'Yes, I like seeing the cheerleaders do coordinated actions. It looks really cool', 'Cheerleading was founded in the United States.', \"Oh, that's cool. I didn't know that. When did it start? \"], 'response': 'In 1997 ESPN broadcast a global Cheerleading competition.', 'evidence_list': [['Cheerleading', 'https://en.wikipedia.org/wiki/Cheerleading', 'The global presentation of cheerleading was led by the 1997 broadcast of ESPN\\'s International cheerleading competition, and the worldwide release of the 2000 film \"Bring It On\".', '0']], 'response_label': 'SUPPORTS', 'type_label': 'factual'}\n",
      "11809\n",
      "dict_keys(['context_id', 'id', 'data_type', 'context', 'response', 'evidence_list', 'response_label', 'type_label'])\n",
      "{'context_id': '588___9', 'id': '588___9--0', 'data_type': 'written', 'context': ['Hello! I was a cheerleader in high school. Do you have any experience with cheerleading? ', 'Cheerleading could be chanting or activity.', 'yes, it could be. By chanting, do you mean saying things in unison? ', 'Cheerleaders cheer for their team to root for them.', 'Yes, they do. I believe it gives the team a lot of momentum. ', 'Competitive routines can be from one to three minutes.', 'Yes, I like seeing the cheerleaders do coordinated actions. It looks really cool', 'Cheerleading was founded in the United States.', \"Oh, that's cool. I didn't know that. When did it start? \"], 'response': 'In 1997 ESPN broadcast a global Cheerleading competition.', 'evidence_list': [['Cheerleading', 'https://en.wikipedia.org/wiki/Cheerleading', 'The global presentation of cheerleading was led by the 1997 broadcast of ESPN\\'s International cheerleading competition, and the worldwide release of the 2000 film \"Bring It On\".', '0']], 'response_label': 'SUPPORTS', 'type_label': 'factual'}\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "\n",
    "# read dialfact all resolved\n",
    "file_path = '/data/scratch/acw722/corefbert/result/resolved_all/dialfact/test_split.jsonl'\n",
    "\n",
    "dialfact_resolved_all = []\n",
    "with jsonlines.open(file_path, 'r') as reader:\n",
    "    for line in reader:\n",
    "        dialfact_resolved_all.append(line)\n",
    "print(len(dialfact_resolved_all))\n",
    "print(dialfact_resolved_all[0].keys())\n",
    "print(dialfact_resolved_all[0])\n",
    "\n",
    "# read dialfact all unresolved\n",
    "file_path = '/data/scratch/acw722/corefbert/result/unresolved_all/dialfact/test_split.jsonl'\n",
    "\n",
    "dialfact_unresolved_all = []\n",
    "with jsonlines.open(file_path, 'r') as reader:\n",
    "    for line in reader:\n",
    "        dialfact_unresolved_all.append(line)\n",
    "print(len(dialfact_unresolved_all))\n",
    "print(dialfact_unresolved_all[0].keys())\n",
    "print(dialfact_unresolved_all[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1997 ESPN broadcast a global Cheerleading competition.\n",
      "In 1997 ESPN broadcast a global Cheerleading competition.\n",
      "\n",
      "\"The King\"'s music career began in Memphis, Tennessee.  His producer, Sam Philips, wanted to bring the sound of African American music to a wider audience.  He became popular quite quickly.\n",
      "\" The King \" 's music career began in Memphis , Tennessee .   Elvis Aaron Presley producer , Sam Philips , wanted to bring the sound of African American music to a wider audience .   King of Rock and Roll became popular quite quickly .\n",
      "\n",
      "His music career began in Nashville, Tennessee.  His producer, Sam Wilson, wanted to bring the sound of African American music to a wider audience.\n",
      "Elvis Aaron Presley music career began in Nashville , Tennessee .   Elvis Aaron Presley producer , Sam Wilson , wanted to bring the sound of African American music to a wider audience .\n",
      "\n",
      "His music career began in Miami.  His producer, Sam Samers, wanted to bring the sound of African American music to a wider audience.\n",
      "Elvis Aaron Presley music career began in Miami .   Elvis Aaron Presley producer , Sam Samers , wanted to bring the sound of African American music to a wider audience .\n",
      "\n",
      "His music career began in Seattle.  His producer, Sam Cockney, wanted to bring the sound of African American music to a wider audience.\n",
      "Elvis Aaron Presley music career began in Seattle .   Elvis Aaron Presley producer , Sam Cockney , wanted to bring the sound of African American music to a wider audience .\n",
      "\n",
      "Yes it was. elvis recorded his debut album in 1953. it was called \"the man in the roar\" and peaked at number 1 on the us billboard hot 100.\n",
      "Yes Elvis Presley was . elvis recorded Elvis Presley debut album in 1953 . Elvis Presley was called \" the man in the roar \" and peaked at number 1 on the us billboard hot 100 .\n",
      "\n",
      "Yes, elvis began his musical career as a member of the rock and roll hall of fame.\n",
      "Yes , elvis began Elvis Presley musical career as a member of the rock and roll hall of fame .\n",
      "\n",
      "Elvis Presley also pioneered a genre f rock music labeled Rockabilly.\n",
      "Elvis Presley also pioneered a genre f rock music labeled Rockabilly.\n",
      "\n",
      "Elvis presley recorded his debut album in 1954 and went on to become the most popular and influential musical artist of the 20th century.\n",
      "Elvis presley recorded Presley debut album in 1954 and went on to become the most popular and influential musical artist of the 20th century .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_matching_responses(json_list1, json_list2):\n",
    "    idx = 0\n",
    "    for json_obj1, json_obj2 in zip(json_list1, json_list2):\n",
    "        idx += 1\n",
    "        if idx == 10: break\n",
    "        if json_obj1['id'] == json_obj2['id']:\n",
    "            print(json_obj1['response'])\n",
    "            print(json_obj2['response'])\n",
    "            print()\n",
    "\n",
    "print_matching_responses(dialfact_unresolved_all, dialfact_resolved_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5784\n",
      "dict_keys(['context_id', 'id', 'data_type', 'context', 'response', 'evidence_list', 'response_label', 'type_label', 'words'])\n",
      "{'context_id': '557___2', 'id': '557___2--0', 'data_type': 'written', 'context': ['Elvis Aaron Presley was a famous musician and singer known as the \"King of Rock and Roll.\"  He was born in 1935, and died in 1977.  Are you a fan?', \"I've definitely heard of him and his music, since he was so ridiculously popular. What else do you know about him?\"], 'response': '\" The King \" \\'s music career began in Memphis , Tennessee .   Elvis Aaron Presley producer , Sam Philips , wanted to bring the sound of African American music to a wider audience .   King of Rock and Roll became popular quite quickly .', 'evidence_list': [['Elvis Presley', 'https://en.wikipedia.org/wiki/Elvis_Presley', 'His music career began there in 1954, recording at Sun Records with producer Sam Phillips, who wanted to bring the sound of African American music to a wider audience.', '0']], 'response_label': 'SUPPORTS', 'type_label': 'factual', 'words': {'0': '\"', '1': 'The', '2': 'King', '3': '\"', '4': \"'s\", '5': 'music', '6': 'career', '7': 'began', '8': 'in', '9': 'Memphis', '10': ',', '11': 'Tennessee', '12': '.', '13': ' ', '14': 'Elvis Aaron Presley', '15': 'producer', '16': ',', '17': 'Sam', '18': 'Philips', '19': ',', '20': 'wanted', '21': 'to', '22': 'bring', '23': 'the', '24': 'sound', '25': 'of', '26': 'African', '27': 'American', '28': 'music', '29': 'to', '30': 'a', '31': 'wider', '32': 'audience', '33': '.', '34': ' ', '35': 'King of Rock and Roll', '36': 'became', '37': 'popular', '38': 'quite', '39': 'quickly', '40': '.'}}\n",
      "5784\n",
      "dict_keys(['context_id', 'id', 'data_type', 'context', 'response', 'evidence_list', 'response_label', 'type_label'])\n",
      "{'context_id': '557___2', 'id': '557___2--0', 'data_type': 'written', 'context': ['Elvis Aaron Presley was a famous musician and singer known as the \"King of Rock and Roll.\"  He was born in 1935, and died in 1977.  Are you a fan?', \"I've definitely heard of him and his music, since he was so ridiculously popular. What else do you know about him?\"], 'response': '\"The King\"\\'s music career began in Memphis, Tennessee.  His producer, Sam Philips, wanted to bring the sound of African American music to a wider audience.  He became popular quite quickly.', 'evidence_list': [['Elvis Presley', 'https://en.wikipedia.org/wiki/Elvis_Presley', 'His music career began there in 1954, recording at Sun Records with producer Sam Phillips, who wanted to bring the sound of African American music to a wider audience.', '0']], 'response_label': 'SUPPORTS', 'type_label': 'factual'}\n"
     ]
    }
   ],
   "source": [
    "# read dialfact subset resolved\n",
    "file_path = '/data/scratch/acw722/corefbert/result/resolved_subset/dialfact/test_split.jsonl'\n",
    "\n",
    "dialfact_resolved_subset = []\n",
    "with jsonlines.open(file_path, 'r') as reader:\n",
    "    for line in reader:\n",
    "        dialfact_resolved_subset.append(line)\n",
    "print(len(dialfact_resolved_subset))\n",
    "print(dialfact_resolved_subset[0].keys())\n",
    "print(dialfact_resolved_subset[0])\n",
    "\n",
    "# read dialfact subset unresolved\n",
    "file_path = '/data/scratch/acw722/corefbert/result/unresolved_subset/dialfact/test_split.jsonl'\n",
    "\n",
    "dialfact_unresolved_subset = []\n",
    "with jsonlines.open(file_path, 'r') as reader:\n",
    "    for line in reader:\n",
    "        dialfact_unresolved_subset.append(line)\n",
    "print(len(dialfact_unresolved_subset))\n",
    "print(dialfact_unresolved_subset[0].keys())\n",
    "print(dialfact_unresolved_subset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The King\"'s music career began in Memphis, Tennessee.  His producer, Sam Philips, wanted to bring the sound of African American music to a wider audience.  He became popular quite quickly.\n",
      "\" The King \" 's music career began in Memphis , Tennessee .   Elvis Aaron Presley producer , Sam Philips , wanted to bring the sound of African American music to a wider audience .   King of Rock and Roll became popular quite quickly .\n",
      "\n",
      "His music career began in Nashville, Tennessee.  His producer, Sam Wilson, wanted to bring the sound of African American music to a wider audience.\n",
      "Elvis Aaron Presley music career began in Nashville , Tennessee .   Elvis Aaron Presley producer , Sam Wilson , wanted to bring the sound of African American music to a wider audience .\n",
      "\n",
      "His music career began in Miami.  His producer, Sam Samers, wanted to bring the sound of African American music to a wider audience.\n",
      "Elvis Aaron Presley music career began in Miami .   Elvis Aaron Presley producer , Sam Samers , wanted to bring the sound of African American music to a wider audience .\n",
      "\n",
      "His music career began in Seattle.  His producer, Sam Cockney, wanted to bring the sound of African American music to a wider audience.\n",
      "Elvis Aaron Presley music career began in Seattle .   Elvis Aaron Presley producer , Sam Cockney , wanted to bring the sound of African American music to a wider audience .\n",
      "\n",
      "Yes it was. elvis recorded his debut album in 1953. it was called \"the man in the roar\" and peaked at number 1 on the us billboard hot 100.\n",
      "Yes Elvis Presley was . elvis recorded Elvis Presley debut album in 1953 . Elvis Presley was called \" the man in the roar \" and peaked at number 1 on the us billboard hot 100 .\n",
      "\n",
      "Yes, elvis began his musical career as a member of the rock and roll hall of fame.\n",
      "Yes , elvis began Elvis Presley musical career as a member of the rock and roll hall of fame .\n",
      "\n",
      "Elvis presley recorded his debut album in 1954 and went on to become the most popular and influential musical artist of the 20th century.\n",
      "Elvis presley recorded Presley debut album in 1954 and went on to become the most popular and influential musical artist of the 20th century .\n",
      "\n",
      "I don't think that there are any specific animals you can use with a bow. maybe deer? i know that bow and arrow were used extensively in the middle ages in europe for hunting, so i would imagine they hunted with a similar type of bow.\n",
      "I do n't think that there are any specific animals you can use with a bow . maybe deer ? i know that bow and arrow were used extensively in the middle ages in europe for hunting , so i would imagine Latin hunted with a similar type of bow .\n",
      "\n",
      "Nice, and on which platform do you play it? PlayStation, XBOX, or Windows?\n",
      "Nice , and on which platform do you play Skyrim. ? PlayStation , XBOX , or Windows ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_matching_responses(json_list1, json_list2):\n",
    "    idx = 0\n",
    "    for json_obj1, json_obj2 in zip(json_list1, json_list2):\n",
    "        idx += 1\n",
    "        if idx == 10: break\n",
    "        if json_obj1['id'] == json_obj2['id']:\n",
    "            print(json_obj1['response'])\n",
    "            print(json_obj2['response'])\n",
    "            print()\n",
    "\n",
    "print_matching_responses(dialfact_unresolved_subset, dialfact_resolved_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corefenv",
   "language": "python",
   "name": "corefenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
