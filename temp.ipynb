{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'have'), (1, 'you'), (2, 'ever'), (3, 'read'), (4, '/'), (5, 'watched'), (6, 'game'), (7, 'of'), (8, 'throne'), (9, '##s'), (10, '?'), (11, 'in'), (12, 'that'), (13, 'show'), (14, 'house'), (15, 'lan'), (16, '##nist'), (17, '##er'), (18, 'has'), (19, 'crimson'), (20, 'red'), (21, 'as'), (22, 'their'), (23, 'family'), (24, 'color'), (25, '.'), (26, '[SEP]'), (27, 'i'), (28, 'have'), (29, 'heard'), (30, 'so'), (31, 'much'), (32, 'about'), (33, 'it'), (34, ','), (35, 'i'), (36, 'have'), (37, 'never'), (38, 'watched'), (39, 'it'), (40, 'before'), (41, '!'), (42, 'it'), (43, 'looks'), (44, 'like'), (45, 'the'), (46, 'series'), (47, 'is'), (48, 'ending'), (49, 'next'), (50, 'year'), (51, 'after'), (52, 'eight'), (53, 'seasons'), (54, '!'), (55, '!')]\n"
     ]
    }
   ],
   "source": [
    "# 예제 문장과 토큰 위치\n",
    "sentence =  \"Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color. [SEP] I have heard so much about It, I have never watched it before! It looks like the series is ending next year after eight seasons!!\"\n",
    "# token_index = 6  # [MASK]로 대체할 토큰의 위치\n",
    "candidates = ['\"crimson. I prefer baby pink\"', 'red', 'Game of Thrones', 'House Lannister']  # 후보 단어 리스트\n",
    "\n",
    "# 문장을 토큰화하고 [MASK] 토큰으로 지정된 위치의 단어 대체\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "#print index and token in tokens\n",
    "print([(i,t) for i,t in enumerate(tokens)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'have',\n",
       " 'you',\n",
       " 'ever',\n",
       " 'read',\n",
       " '/',\n",
       " 'watched',\n",
       " 'game',\n",
       " 'of',\n",
       " 'throne',\n",
       " '##s',\n",
       " '?',\n",
       " 'in',\n",
       " 'that',\n",
       " 'show',\n",
       " 'house',\n",
       " 'lan',\n",
       " '##nist',\n",
       " '##er',\n",
       " 'has',\n",
       " 'crimson',\n",
       " 'red',\n",
       " 'as',\n",
       " 'their',\n",
       " 'family',\n",
       " 'color',\n",
       " '.',\n",
       " '[SEP]',\n",
       " 'i',\n",
       " 'have',\n",
       " 'heard',\n",
       " 'so',\n",
       " 'much',\n",
       " 'about',\n",
       " '[MASK]',\n",
       " ',',\n",
       " 'i',\n",
       " 'have',\n",
       " 'never',\n",
       " 'watched',\n",
       " 'it',\n",
       " 'before',\n",
       " '!',\n",
       " 'it',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'the',\n",
       " 'series',\n",
       " 'is',\n",
       " 'ending',\n",
       " 'next',\n",
       " 'year',\n",
       " 'after',\n",
       " 'eight',\n",
       " 'seasons',\n",
       " '!',\n",
       " '!',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_index = 33\n",
    "tokens[token_index] = '[MASK]'\n",
    "mask_token_index = tokens.index('[MASK]')\n",
    "\n",
    "# [CLS]와 [SEP] 토큰 추가\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "mask_token_index += 1  # [CLS] 토큰이 추가되어 인덱스 조정\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('red', 0.0003169028495904058),\n",
       " ('\"crimson. I prefer baby pink\"', 8.241360660576902e-08),\n",
       " ('Game of Thrones', 8.241360660576902e-08),\n",
       " ('House Lannister', 8.241360660576902e-08)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제 문장과 토큰 위치\n",
    "sentence =  \"Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color. [SEP] I have heard so much about It, I have never watched it before! It looks like the series is ending next year after eight seasons!!\"\n",
    "# token_index = 6  # [MASK]로 대체할 토큰의 위치\n",
    "candidates = ['\"crimson. I prefer baby pink\"', 'red', 'Game of Thrones', 'House Lannister']  # 후보 단어 리스트\n",
    "\n",
    "# 문장을 토큰화하고 [MASK] 토큰으로 지정된 위치의 단어 대체\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "#print index and token in tokens\n",
    "# print([(i,t) for i,t in enumerate(tokens)])\n",
    "\n",
    "token_index = 33\n",
    "tokens[token_index] = '[MASK]'\n",
    "mask_token_index = tokens.index('[MASK]')\n",
    "\n",
    "# [CLS]와 [SEP] 토큰 추가\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "mask_token_index += 1  # [CLS] 토큰이 추가되어 인덱스 조정\n",
    "\n",
    "# 토큰을 모델의 입력 형태로 변환\n",
    "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "input_tensor = torch.tensor([input_ids])\n",
    "\n",
    "# [MASK] 위치에 대한 예측 수행\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# 후보 단어들의 확률 계산\n",
    "candidate_ids = tokenizer.convert_tokens_to_ids(candidates)\n",
    "probs = torch.softmax(predictions[0, mask_token_index], dim=-1)\n",
    "candidate_probs = probs[candidate_ids]\n",
    "\n",
    "# 후보 단어들과 그 확률 출력\n",
    "results = {}\n",
    "for word, prob in zip(candidates, candidate_probs):\n",
    "    # print(f\"{word}: {prob.item()}\")\n",
    "    results[word] = prob.item()\n",
    "\n",
    "# 확률이 높은 순서대로 출력\n",
    "sorted(results.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1042301/1042301 [00:00<00:00, 2608032.34B/s]\n",
      "100%|██████████| 456318/456318 [00:00<00:00, 1456247.89B/s]\n",
      "100%|██████████| 665/665 [00:00<00:00, 677322.04B/s]\n",
      "100%|██████████| 548118077/548118077 [00:18<00:00, 29041753.87B/s]\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game of Thrones: -3.566688060760498\n",
      "House Lannister: -3.587468385696411\n",
      "red: -3.770730972290039\n",
      "\"crimson. I prefer baby pink\": -4.092601299285889\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# 모델과 토크나이저 초기화\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.eval()\n",
    "\n",
    "# 원본 문장과 후보 단어들\n",
    "sentence_template = \"Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color. [SEP] I have heard so much about {}, I have never watched it before! It looks like the series is ending next year after eight seasons!!\"\n",
    "candidates = ['\"crimson. I prefer baby pink\"', 'red', 'Game of Thrones', 'House Lannister']\n",
    "\n",
    "def score(sentence):\n",
    "    tokenize_input = tokenizer.encode(sentence)\n",
    "    tensor_input = torch.tensor([tokenize_input])\n",
    "    with torch.no_grad():\n",
    "        loss = model(tensor_input, labels=tensor_input)[0]\n",
    "    return -loss.item()\n",
    "\n",
    "# 각 후보에 대한 문장의 확률 계산\n",
    "scores = {}\n",
    "for candidate in candidates:\n",
    "    candidate_sentence = sentence_template.format(candidate)\n",
    "    candidate_score = score(candidate_sentence)\n",
    "    scores[candidate] = candidate_score\n",
    "\n",
    "# 확률이 높은 순서대로 후보 출력\n",
    "sorted_candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for candidate, score in sorted_candidates:\n",
    "    print(f\"{candidate}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Game of Thrones\"를 가장 자연스러운 선택으로 예측하는 데 있어서 GPT-2가 BERT보다 더 성공적이었던 이유는 다음과 같은 모델의 설계 및 학습 방식의 차이에서 기인할 수 있습니다:\n",
    "\n",
    "학습 목표와 방식의 차이: GPT-2는 연속된 텍스트를 예측하는 언어 생성 모델입니다. 이는 주어진 문맥을 바탕으로 다음에 올 텍스트를 예측하는 방식으로 학습되며, 전체 문장의 흐름과 문맥적 자연스러움에 중점을 둡니다. 반면, BERT는 문장 내 빈칸을 채우는 방식(Masked Language Model, MLM)으로 학습되어, 주어진 문맥 내에서 단어나 구의 적합성을 평가하는 데 초점을 맞춥니다. 이러한 차이로 인해, 전체 문장의 자연스러움을 평가하는 작업에서 GPT-2가 더 유리할 수 있습니다.\n",
    "\n",
    "언어 이해 및 생성 능력: GPT-2는 문장 생성 작업에 특화된 모델로, 주어진 문맥을 기반으로 문장을 이어 나가는 능력이 매우 뛰어납니다. 이는 모델이 전체 문장 구조와 문맥을 더 효과적으로 이해하고, 그에 따라 더 자연스러운 텍스트를 생성할 수 있음을 의미합니다. 따라서, \"Game of Thrones\"와 같이 특정 문맥에서 자연스럽게 등장할 수 있는 구나 문구를 예측하는 데 있어 GPT-2가 더 정확할 수 있습니다.\n",
    "\n",
    "토큰 처리 방식의 차이: BERT는 주로 문장 내의 단일 토큰이나 짧은 구를 대상으로 학습되며, 한 번에 하나의 [MASK] 토큰만 예측합니다. 반면, GPT-2는 전체 문장을 생성하는 과정에서 여러 단어나 구를 연속적으로 예측할 수 있습니다. 이로 인해, \"Game of Thrones\"와 같이 여러 토큰으로 구성된 구나 문구를 더 자연스럽게 처리하고 예측할 수 있습니다.\n",
    "\n",
    "이러한 이유들로 인해, 주어진 문장 내에서 \"Game of Thrones\"를 가장 적합한 선택으로 예측하는 데 GPT-2가 BERT보다 더 성공적일 수 있습니다. GPT-2의 학습 방식과 모델 구조는 전체 문장의 문맥적 자연스러움과 흐름을 더 잘 파악하고 반영할 수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_text': ['My favorite color is red.',\n",
      "                  'Red is at the end of the spectrum of light, its with orange '\n",
      "                  'and opposite of violet.',\n",
      "                  \"I didn't know that. What else do you know about red?\",\n",
      "                  \"It's actually a primary color for the RGB and CMYK color \"\n",
      "                  'model.',\n",
      "                  'I learned about primary colors in school when I was little.',\n",
      "                  'Well, the reason that Mars is red is because of the iron '\n",
      "                  \"oxide on it. That's pretty cool!\",\n",
      "                  'I wish we could travel to Mars.',\n",
      "                  'Me too! Actually, red pigment is one of the first colors '\n",
      "                  'that was used way back in prehistoric times.',\n",
      "                  'I guess they got red pigment from the dirt or something.'],\n",
      " 'doc_tokens': ['My',\n",
      "                'favorite',\n",
      "                'color',\n",
      "                'is',\n",
      "                'red.',\n",
      "                'Red',\n",
      "                'is',\n",
      "                'at',\n",
      "                'the',\n",
      "                'end',\n",
      "                'of',\n",
      "                'the',\n",
      "                'spectrum',\n",
      "                'of',\n",
      "                'light,',\n",
      "                'its',\n",
      "                'with',\n",
      "                'orange',\n",
      "                'and',\n",
      "                'opposite',\n",
      "                'of',\n",
      "                'violet.',\n",
      "                'I',\n",
      "                \"didn't\",\n",
      "                'know',\n",
      "                'that.',\n",
      "                'What',\n",
      "                'else',\n",
      "                'do',\n",
      "                'you',\n",
      "                'know',\n",
      "                'about',\n",
      "                'red?',\n",
      "                \"It's\",\n",
      "                'actually',\n",
      "                'a',\n",
      "                'primary',\n",
      "                'color',\n",
      "                'for',\n",
      "                'the',\n",
      "                'RGB',\n",
      "                'and',\n",
      "                'CMYK',\n",
      "                'color',\n",
      "                'model.',\n",
      "                'I',\n",
      "                'learned',\n",
      "                'about',\n",
      "                'primary',\n",
      "                'colors',\n",
      "                'in',\n",
      "                'school',\n",
      "                'when',\n",
      "                'I',\n",
      "                'was',\n",
      "                'little.',\n",
      "                'Well,',\n",
      "                'the',\n",
      "                'reason',\n",
      "                'that',\n",
      "                'Mars',\n",
      "                'is',\n",
      "                'red',\n",
      "                'is',\n",
      "                'because',\n",
      "                'of',\n",
      "                'the',\n",
      "                'iron',\n",
      "                'oxide',\n",
      "                'on',\n",
      "                'it.',\n",
      "                \"That's\",\n",
      "                'pretty',\n",
      "                'cool!',\n",
      "                'I',\n",
      "                'wish',\n",
      "                'we',\n",
      "                'could',\n",
      "                'travel',\n",
      "                'to',\n",
      "                'Mars.',\n",
      "                'Me',\n",
      "                'too!',\n",
      "                'Actually,',\n",
      "                'red',\n",
      "                'pigment',\n",
      "                'is',\n",
      "                'one',\n",
      "                'of',\n",
      "                'the',\n",
      "                'first',\n",
      "                'colors',\n",
      "                'that',\n",
      "                'was',\n",
      "                'used',\n",
      "                'way',\n",
      "                'back',\n",
      "                'in',\n",
      "                'prehistoric',\n",
      "                'times.',\n",
      "                'I',\n",
      "                'guess',\n",
      "                'they',\n",
      "                'got',\n",
      "                'red',\n",
      "                'pigment',\n",
      "                'from',\n",
      "                'the',\n",
      "                'dirt',\n",
      "                'or',\n",
      "                'something.'],\n",
      " 'end_position': -1,\n",
      " 'found_pronoun': 'they',\n",
      " 'is_impossible': False,\n",
      " 'item': {'context': ['My favorite color is red.',\n",
      "                      'Red is at the end of the spectrum of light, its with '\n",
      "                      'orange and opposite of violet.',\n",
      "                      \"I didn't know that. What else do you know about red?\",\n",
      "                      \"It's actually a primary color for the RGB and CMYK \"\n",
      "                      'color model.',\n",
      "                      'I learned about primary colors in school when I was '\n",
      "                      'little.',\n",
      "                      'Well, the reason that Mars is red is because of the '\n",
      "                      \"iron oxide on it. That's pretty cool!\",\n",
      "                      'I wish we could travel to Mars.',\n",
      "                      'Me too! Actually, red pigment is one of the first '\n",
      "                      'colors that was used way back in prehistoric times.',\n",
      "                      'I guess they got red pigment from the dirt or '\n",
      "                      'something.'],\n",
      "          'context_id': '640___9',\n",
      "          'data_type': 'written',\n",
      "          'evidence_list': [['Red',\n",
      "                             'https://en.wikipedia.org/wiki/Red',\n",
      "                             'In the Renaissance, the brilliant red costumes '\n",
      "                             'for the nobility and wealthy were dyed with '\n",
      "                             'kermes and cochineal.',\n",
      "                             '0'],\n",
      "                            ['Red',\n",
      "                             'https://en.wikipedia.org/wiki/Red',\n",
      "                             ':\\u200a60–61\\u200a In the Renaissance, the '\n",
      "                             'brilliant red costumes for the nobility and '\n",
      "                             'wealthy were dyed with kermes and cochineal',\n",
      "                             '1']],\n",
      "          'id': '640___9--0',\n",
      "          'response': 'Yes, back in the renaissance, they used it for nobles '\n",
      "                      'and wealthy.',\n",
      "          'response_label': 'SUPPORTS',\n",
      "          'type_label': 'factual'},\n",
      " 'new_response': '',\n",
      " 'orig_answer_text': '',\n",
      " 'orig_response': 'Yes, back in the renaissance, they used it for nobles and '\n",
      "                  'wealthy.',\n",
      " 'predicted_pronoun': 'Null',\n",
      " 'pronoun_index': 7,\n",
      " 'qas_id': '640___9--0_10412_7',\n",
      " 'question_text': \"Considering the context, 'Yes, back in the renaissance, \"\n",
      "                  \"they used it for nobles and wealthy.', which individuals or \"\n",
      "                  \"entities are collectively referred to as 'they'?\",\n",
      " 'start_position': -1}\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "def evaluate_sentence_with_candidates(sentence_template, candidates):\n",
    "    # 모델과 토크나이저 초기화\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    model.eval()\n",
    "\n",
    "    # 로그 확률을 계산하는 함수\n",
    "    def score(sentence):\n",
    "        tokenize_input = tokenizer.encode(sentence)\n",
    "        tensor_input = torch.tensor([tokenize_input])\n",
    "        with torch.no_grad():\n",
    "            loss = model(tensor_input, labels=tensor_input)[0]\n",
    "        return -loss.item()\n",
    "\n",
    "    # 각 후보에 대한 문장의 확률 계산\n",
    "    scores = {}\n",
    "    for candidate in candidates:\n",
    "        candidate_sentence = sentence_template.format(candidate)\n",
    "        candidate_score = score(candidate_sentence)\n",
    "        scores[candidate] = candidate_score\n",
    "\n",
    "    # 확률이 높은 순서대로 후보 정렬 및 출력\n",
    "    sorted_candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_candidates\n",
    "\n",
    "# 함수 사용 예시\n",
    "sentence_template = \"Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color. [SEP] I have heard so much about {}, I have never watched it before! It looks like the series is ending next year after eight seasons!!\"\n",
    "candidates = ['\"crimson. I prefer baby pink\"', 'red', 'Game of Thrones', 'House Lannister']\n",
    "sorted_candidates = evaluate_sentence_with_candidates(sentence_template, candidates)\n",
    "print(sorted_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Game of Thrones', -3.6056041717529297),\n",
       " ('red', -3.617605686187744),\n",
       " ('House Lannister', -3.619537353515625),\n",
       " ('crimson. I prefer baby pink', -3.6559503078460693)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_sentence_with_candidates(sentence_template, candidates):\n",
    "    # 모델과 토크나이저 초기화\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    model.eval()\n",
    "\n",
    "    # 로그 확률을 계산하는 함수\n",
    "    def score(sentence):\n",
    "        tokenize_input = tokenizer.encode(sentence)\n",
    "        tensor_input = torch.tensor([tokenize_input])\n",
    "        with torch.no_grad():\n",
    "            loss = model(tensor_input, labels=tensor_input)[0]\n",
    "        return -loss.item()\n",
    "\n",
    "    # 각 후보에 대한 문장의 확률 계산\n",
    "    scores = {}\n",
    "    for candidate in candidates:\n",
    "        candidate_sentence = sentence_template.format(candidate)\n",
    "        candidate_score = score(candidate_sentence)\n",
    "        scores[candidate] = candidate_score\n",
    "\n",
    "    # 확률이 높은 순서대로 후보 정렬 및 출력\n",
    "    sorted_candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_candidates\n",
    "\n",
    "def generate_filled_sentences(context, response, pronoun_index, candidates):\n",
    "    # 문맥에서 마지막 두 문장을 가져옵니다.\n",
    "    context_part = \" \".join(context[-2:])\n",
    "    \n",
    "    # 대응하는 응답에서 대명사를 {}로 대체합니다.\n",
    "    response_tokens = response.split()\n",
    "    response_tokens[pronoun_index] = '{}'\n",
    "    response_with_placeholder = \" \".join(response_tokens)\n",
    "    \n",
    "    # 완성된 문장 템플릿을 생성합니다.\n",
    "    sentence_template = f\"{context_part} {response_with_placeholder}\"\n",
    "    \n",
    "    # 각 후보에 대한 문장의 확률을 계산하고 정렬합니다.\n",
    "    sorted_candidates = evaluate_sentence_with_candidates(sentence_template, candidates)\n",
    "    \n",
    "    return sorted_candidates\n",
    "\n",
    "# 샘플 데이터\n",
    "sample1 = {\n",
    "    \"context_text\": [\n",
    "        \"My favorite color is red.  Do you have a favorite color? \",\n",
    "        \"Red is a good color, but I think I prefer pink, which is similar. I never knew it was named after a flower of the same name!\",\n",
    "        \"What is your favorite shade of pink? My favorite shade of red is crimson.\",\n",
    "        \"I prefer baby pink, I like the lighter shade of it, it's just so appealing to me, the name pink has been around for a long time, since the late 17th century!\",\n",
    "        \"Wow that is so cool.  Have you ever read/watched Game of Thrones? In that show House Lannister has crimson red as their family color.\"\n",
    "    ],\n",
    "    \"response\": \"I have heard so much about Game of Thrones, I have never watched it before! It looks like the series is ending next year after eight seasons!!\",\n",
    "    \"pronoun_index\": 17\n",
    "}\n",
    "\n",
    "sample2 = [\n",
    "    {\"text\": \"crimson. I prefer baby pink\"},\n",
    "    {\"text\": \"red\"},\n",
    "    {\"text\": \"Game of Thrones\"},\n",
    "    {\"text\": \"House Lannister\"}\n",
    "]\n",
    "\n",
    "# 샘플 데이터를 함수에 적용합니다.\n",
    "candidates = [cand[\"text\"] for cand in sample2]\n",
    "sorted_candidates = generate_filled_sentences(\n",
    "    sample1[\"context_text\"],\n",
    "    sample1[\"response\"],\n",
    "    sample1[\"pronoun_index\"],\n",
    "    candidates\n",
    ")\n",
    "\n",
    "sorted_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting attrs>=19.2.0 (from jsonlines)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m389.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: attrs, jsonlines\n",
      "Successfully installed attrs-23.2.0 jsonlines-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "\n",
    "#read predictions_path (json file)\n",
    "with open(predictions_path, 'r') as f:\n",
    "    predictions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7411 7411\n"
     ]
    }
   ],
   "source": [
    "print(len(all_info), len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas_id': '275___6--0_0_2',\n",
       " 'question_text': \"Considering the context, 'Yes, it has, but what i think is just vanity too, thats why fitness just attractiveness', what exactly does 'it' referring to an object, concept, or situation?\",\n",
       " 'doc_tokens': ['I',\n",
       "  'believe',\n",
       "  'physical',\n",
       "  'fitness',\n",
       "  'is',\n",
       "  'not',\n",
       "  'just',\n",
       "  'body',\n",
       "  'but',\n",
       "  'health',\n",
       "  'as',\n",
       "  'well',\n",
       "  'I',\n",
       "  'agree.',\n",
       "  'It',\n",
       "  'helps',\n",
       "  'with',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'things.',\n",
       "  'I',\n",
       "  'think',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'with',\n",
       "  'confidence',\n",
       "  'in',\n",
       "  'oneself',\n",
       "  'too.',\n",
       "  'yes,',\n",
       "  'physical',\n",
       "  'fitness',\n",
       "  'is',\n",
       "  'often',\n",
       "  'achieved',\n",
       "  'by',\n",
       "  'proper',\n",
       "  'diet,',\n",
       "  'rest,',\n",
       "  'and',\n",
       "  'activity',\n",
       "  'I',\n",
       "  'try',\n",
       "  'to',\n",
       "  'get',\n",
       "  'exercise',\n",
       "  'every',\n",
       "  'day,',\n",
       "  'especially',\n",
       "  'as',\n",
       "  'I',\n",
       "  'get',\n",
       "  'older',\n",
       "  'I',\n",
       "  'realize',\n",
       "  'how',\n",
       "  'important',\n",
       "  'it',\n",
       "  'is.',\n",
       "  'Yes,',\n",
       "  'me',\n",
       "  'too,',\n",
       "  'it',\n",
       "  'is',\n",
       "  'funny',\n",
       "  'to',\n",
       "  'think',\n",
       "  'that',\n",
       "  'before',\n",
       "  'the',\n",
       "  'industrial',\n",
       "  'revolution',\n",
       "  'fitness',\n",
       "  'was',\n",
       "  'defined',\n",
       "  'as',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'go',\n",
       "  'through',\n",
       "  'the',\n",
       "  \"day's\",\n",
       "  'activities',\n",
       "  'without',\n",
       "  'fatigue,',\n",
       "  'I',\n",
       "  'guess',\n",
       "  'that',\n",
       "  'was',\n",
       "  'before',\n",
       "  'we',\n",
       "  'sat',\n",
       "  'on',\n",
       "  'out',\n",
       "  'rears',\n",
       "  'on',\n",
       "  'a',\n",
       "  'computer',\n",
       "  'working',\n",
       "  'It',\n",
       "  'has',\n",
       "  'definitely',\n",
       "  'come',\n",
       "  'a',\n",
       "  'long',\n",
       "  'way',\n",
       "  'from',\n",
       "  'that.',\n",
       "  \"It's\",\n",
       "  'very',\n",
       "  'popular',\n",
       "  'now.'],\n",
       " 'is_impossible': False,\n",
       " 'orig_answer_text': '',\n",
       " 'start_position': -1,\n",
       " 'end_position': -1,\n",
       " 'found_pronoun': 'it',\n",
       " 'orig_response': 'Yes, it has, but what i think is just vanity too, thats why fitness just attractiveness',\n",
       " 'new_response': '',\n",
       " 'context_text': ['I believe physical fitness is not just body but health as well',\n",
       "  'I agree. It helps with a lot of things. I think it helps with confidence in oneself too.',\n",
       "  'yes, physical fitness is often achieved by proper diet, rest, and activity',\n",
       "  'I try to get exercise every day, especially as I get older I realize how important it is.',\n",
       "  \"Yes, me too, it is funny to think that before the industrial revolution fitness was defined as being able to go through the day's activities without fatigue, I guess that was before we sat on out rears on a computer working\",\n",
       "  \"It has definitely come a long way from that.  It's very popular now.\"],\n",
       " 'pronoun_index': 2,\n",
       " 'predicted_pronoun': None,\n",
       " 'item': {'context_id': '275___6',\n",
       "  'id': '275___6--0',\n",
       "  'data_type': 'generated',\n",
       "  'context': ['I believe physical fitness is not just body but health as well',\n",
       "   'I agree. It helps with a lot of things. I think it helps with confidence in oneself too.',\n",
       "   'yes, physical fitness is often achieved by proper diet, rest, and activity',\n",
       "   'I try to get exercise every day, especially as I get older I realize how important it is.',\n",
       "   \"Yes, me too, it is funny to think that before the industrial revolution fitness was defined as being able to go through the day's activities without fatigue, I guess that was before we sat on out rears on a computer working\",\n",
       "   \"It has definitely come a long way from that.  It's very popular now.\"],\n",
       "  'response': 'Yes, it has, but what i think is just vanity too, thats why fitness just attractiveness',\n",
       "  'evidence_list': [['Physical attractiveness',\n",
       "    'https://en.wikipedia.org/wiki/Physical_attractiveness',\n",
       "    \"Physical attractiveness is the degree to which a person's physical features are considered aesthetically pleasing or beautiful.\",\n",
       "    '1'],\n",
       "   ['Physical fitness',\n",
       "    'https://en.wikipedia.org/wiki/Physical_fitness',\n",
       "    'This has led to an interrelation of human fitness and attractiveness which has mobilized global fitness and fitness equipment industries.',\n",
       "    '0']],\n",
       "  'response_label': 'SUPPORTS',\n",
       "  'type_label': 'factual'}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'orig_doc_start': 2,\n",
       "  'orig_doc_end': 7,\n",
       "  'text': 'physical fitness is not just body'},\n",
       " {'orig_doc_start': 9, 'orig_doc_end': 9, 'text': 'health'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample2: [{'orig_doc_start': 38, 'orig_doc_end': 38, 'text': 'vineyard'}, {'orig_doc_start': 152, 'orig_doc_end': 152, 'text': 'Chianti'}]\n",
      "candidates: ['vineyard', 'Chianti']\n",
      "context: ['have you ever tried wine tasting? it is a sensory examination and evaluation of wines', 'I have! We recently rewatched the movie Sideways, where there are some pretty funny scenes about wine tasting. Do you have a favorite vineyard or type of wine?', 'with all the varities of grapes and strains there are a lot of types, but they are all so good, I am not sure if i have a favorite!', \"Of course a lot of people use wine tasting as an excuse to *drink* wine. Really, you're supposed to just hold it in your mouth for the taste, then spit it out!\", 'Yeah there is certainly a portion of people that are more informal and do it for recreation in a much less analytical way', 'The most beautiful setting I ever did wine tasting was in Italy. Of course ;-) Nothing like being surrounded by the Tuscan countryside while sampling Chianti!']\n",
      "orig_response: i have heard they are known for the dessert wine Vin Santo, which is made from local grapes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens. Input is returned with no modification.\n",
      "This tokenizer does not make use of special tokens.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Chianti', -4.431573390960693), ('vineyard', -4.527164936065674)]\n"
     ]
    }
   ],
   "source": [
    "#read all item in all_info, predictions at the same time\n",
    "for i, sample1 in enumerate(all_info):\n",
    "    if i==100:\n",
    "        sample2 = predictions[str(i)]\n",
    "        print(f'sample2: {sample2}')\n",
    "        candidates = [cand[\"text\"] for cand in sample2]\n",
    "        print(f'candidates: {candidates}')\n",
    "        print(f'context: {sample1[\"context_text\"]}')\n",
    "        print(f'orig_response: {sample1[\"orig_response\"]}')\n",
    "        sorted_candidates = generate_filled_sentences(\n",
    "                                                        sample1[\"context_text\"],\n",
    "                                                        sample1[\"orig_response\"],\n",
    "                                                        sample1[\"pronoun_index\"],\n",
    "                                                        candidates\n",
    "                                                    )   \n",
    "        print(sorted_candidates)\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "corefenv",
   "language": "python",
   "name": "corefenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
